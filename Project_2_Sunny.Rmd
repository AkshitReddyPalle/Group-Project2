---
title: "Project-6101"
author: "Sunny"
date: "2024-11-29"
output: 
  html_document:
    code_folding: show
    toc: yes
    toc_depth: 3
    toc_float: yes
---
```{r init, include=FALSE}
#library(ezids)
library(dplyr)
library(ggplot2)
library(corrplot)
library(car)
library(ranger)
library(pdp)
```




```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F, message = F, results = "markup")
options(scipen=999, digits = 5) 
```

## 1.Data ETL


```{r}
data_raw <- read.csv("C:/Users/qluo/Box/DATS 6101/Group-Project2/Combined_SDOH_2019_2020.csv")
```

```{r}
col_indices <- c('COUNTYFIPS','YEAR','ACS_PCT_FEMALE','ACS_PCT_AGE_15_17',
                 'ACS_PCT_AGE_18_29','ACS_PCT_AGE_30_44',
                 'ACS_PCT_AIAN_NONHISP','ACS_PCT_ASIAN_NONHISP',
                 'ACS_PCT_BLACK_NONHISP',
                 'ACS_PCT_HISPANIC','ACS_PCT_NHPI_NONHISP','ACS_PCT_OTHER_NONHISP',
                 'ACS_PCT_NOT_LABOR','ACS_MEDIAN_HH_INC','ACS_PCT_HEALTH_INC_BELOW137',
                 'AHRF_UNEMPLOYED_RATE','AHRF_NURSE_MIDWIVES_RATE','CDCW_MATERNAL_DTH_RATE',
                 'POS_MEDIAN_DIST_OBSTETRICS','POS_FQHC_RATE',
                 'POS_HOSP_OBSTETRIC_RATE','POS_HOSP_MEDSURG_ICU_RATE','POS_HOSP_ED_RATE','POS_PCT_HOSP_GOV')
 
subset_data <- data_raw[,col_indices]
colnames(subset_data) <- c('countyfips','YEAR','Percent_femal_pop',"Percent_pop_15_17","Percent_pop_18_29","Percent_pop_30_44",
                           'Percent_pop_American_Indian_and_Alaska_Native','Percent_pop_Asian',
                           'Percent_pop_Black_and_African_American','Percent_pop_Hispanic',
                           'Percent_pop_Native_Hawaiian_and_Pacific_Islander','Percent_pop_other_race',
                           "Percent_pop_not_in_labor_force_16",'Median_household_income',
                           'Percent_pop_under_1.37_of_poverty_threshold',
                           "Unemployment_rate_per_100_population_16",
                           'Number_of_midwives','Maternal_mortality_rate',
                           'Median_distance_to_nearest_obstetrics_department','Numer_of_health_centers',
                           'Number_of_hospitals_with_obstetric','Number_of_hospitals_with_ICU',
                           'Number_of_hospitals_with_emergency_department','Percent_government_hospitals')

```
We can divide the variables into different categories, making them clear when showing the independent variables.

## 2. Outcome Imputation

```{r}
print(paste0("Maternal_mortality_rate is missing in ", round(sum(is.na(subset_data$Maternal_mortality_rate))/nrow(subset_data)*100,2),"% of observations."))

print(paste0("Maternal_mortality_rate is 0 in ", round(sum(subset_data$Maternal_mortality_rate==0, na.rm=T)/nrow(subset_data)*100,2),"% of observations."))

```
The highly missing nature of outcome variable *Maternal_mortality_rate* is unexpected. Also, there was no 0 maternal mortality reported in any county. We believe that ARHQ SDOH database is constructed using CDC Wonder's default output settings which suppresses deaths between 1-9 and does not output true zeros. 

We used the following procedure to impute the maternal mortality counts and collaterally the maternal mortality rates.
1. Downloaded the multiple cause maternal mortality for year 2019 and 2020 from CDC Wonder for both state and county level. We made sure that the numbers for non-missing counties matches the record in SDOH database.
2. Downloaded the all cause mortality and underlying cause that is not maternal causes at county level from CDC Wonder. By subtracting the two, we back out the underlying cause mortality due to maternal causes.
3. We used the underlying cause of mortality to distribute the gap between reported county level total mortality and state level total mortality, making sure that states with suppressed mortality has a mortality counts from the larger between underlying cause mortality and 1 to 9 and the counties with true zero maternal mortality stays true zero. 
4. We replace the imputed maternal mortality rate in the original dataframe.

### 2.1 CDC Wonder Data Processing and Imputing 

```{r}
library(readxl)
library(dplyr)
library(stringr)

# Function to clean County and State columns
clean_column <- function(column) {
  column %>%
    str_replace_all("\\*|‡|†| ", "") %>%
    str_trim()
}

# Function to handle iterative adjustments for Stage 3
adjust_imputation <- function(data) {
  # Initialize loop variables
  gap_mean <- mean(data$gap3, na.rm = TRUE)
  counter <- 0
  
  while (gap_mean != 0 & counter < 20) {
    data <- data %>%
      mutate(
        # Step 1: Identify eligible rows for imputation
        impute_elig = ifelse(
          !is.na(all_deaths_under) & is.na(maternal_multi) & between(dist3, 1, 9),
          1,
          0
        )
      ) %>%
      group_by(state_fips) %>%
      mutate(
        # Step 2: Calculate dist3_factor
        dist3_factor = ifelse(
          impute_elig == 1,
          sum(ifelse(impute_elig == 1, impute_weight, NA), na.rm = TRUE),
          NA
        )
      ) %>%
      ungroup() %>%
      mutate(
        # Step 3: Update dist3
        dist3 = ifelse(
          impute_elig == 1,
          ifelse(
            dist3 + (gap3 / dist3_factor * impute_weight) <= 9,
            dist3 + (gap3 / dist3_factor * impute_weight),
            9
          ),
          dist3
        )
      ) %>%
      group_by(state_fips) %>%
      mutate(
        # Step 4: Calculate reported_total3
        reported_total3 = sum(dist3, na.rm = TRUE)
      ) %>%
      ungroup() %>%
      mutate(
        # Step 5: Update gap3
        gap3 = maternal_multi_st - reported_total3
      )
    
    # Update loop variables
    gap_mean <- mean(data$gap3, na.rm = TRUE)
    counter <- counter + 1
  }
  
  return(data)
}

# Process Impute_2019
impute_2019 <- read_excel("MaternalMortality-addtl-data.xlsx", sheet = "Impute_2019") %>%
  mutate(
    population = as.numeric(population),
    County = clean_column(County)
  ) %>%
  filter(!is.na(County)) %>%
  mutate(
    cnty_fips = str_sub(str_sub(County, -7), 2, 6),
    state_fips = str_sub(cnty_fips, 1, 2)
  )

# Process State_2019
state_2019 <- read_excel("MaternalMortality-addtl-data.xlsx", sheet = "State_2019") %>%
  rename(maternal_multi_st = maternal_multi) %>%
  mutate(
    state = clean_column(state),
    state_fips = str_sub(str_sub(state, -3), 1, 2)
  ) %>%
  filter(!is.na(state))

# Merge and process 2019 data
merged_2019 <- left_join(impute_2019, state_2019, by = "state_fips") %>%
  group_by(state_fips) %>%
  mutate(
    # Stage 1: Calculate reported_total1 and gap1
    reported_total1 = sum(maternal_multi, na.rm = TRUE),
    gap1 = maternal_multi_st - reported_total1,
    # Stage 2: Calculate dist2, reported_total2, and gap2
    dist2 = ifelse(
      !is.na(all_deaths_under) & is.na(maternal_multi),
      pmax(maternal_under, 1),
      maternal_multi
    ),
    reported_total2 = sum(dist2, na.rm = TRUE),
    gap2 = maternal_multi_st - reported_total2
  ) %>%
  ungroup() %>%
  mutate(
    # Stage 3: Initialize dist3, gap3, and impute_weight
    dist3 = dist2,
    gap3 = gap2,
    impute_weight = maternal_under + 1
  )

# Apply Stage 3 logic to adjust dist3
merged_2019 <- adjust_imputation(merged_2019) %>%
  mutate(
    maternal_mortality_rate = dist3 / population * 100000,
    year = 2019
  ) %>%
  select(County, cnty_fips, maternal_mortality_rate, year)

# Process Impute_2020
impute_2020 <- read_excel("MaternalMortality-addtl-data.xlsx", sheet = "Impute_2020") %>%
  mutate(
    population = as.numeric(population),
    County = clean_column(County)
  ) %>%
  filter(!is.na(County)) %>%
  mutate(
    cnty_fips = str_sub(str_sub(County, -7), 2, 6),
    state_fips = str_sub(cnty_fips, 1, 2)
  )

# Process State_2020
state_2020 <- read_excel("MaternalMortality-addtl-data.xlsx", sheet = "State_2020") %>%
  rename(maternal_multi_st = maternal_multi) %>%
  mutate(
    state = clean_column(state),
    state_fips = str_sub(str_sub(state, -3), 1, 2)
  ) %>%
  filter(!is.na(state))

# Merge and process 2020 data
merged_2020 <- left_join(impute_2020, state_2020, by = "state_fips") %>%
  group_by(state_fips) %>%
  mutate(
    # Stage 1: Calculate reported_total1 and gap1
    reported_total1 = sum(maternal_multi, na.rm = TRUE),
    gap1 = maternal_multi_st - reported_total1,
    # Stage 2: Calculate dist2, reported_total2, and gap2
    dist2 = ifelse(
      !is.na(all_deaths_under) & is.na(maternal_multi),
      pmax(maternal_under, 1),
      maternal_multi
    ),
    reported_total2 = sum(dist2, na.rm = TRUE),
    gap2 = maternal_multi_st - reported_total2
  ) %>%
  ungroup() %>%
  mutate(
    # Stage 3: Initialize dist3, gap3, and impute_weight
    dist3 = dist2,
    gap3 = gap2,
    impute_weight = maternal_under + 1
  )

# Apply Stage 3 logic to adjust dist3
merged_2020 <- adjust_imputation(merged_2020) %>%
  mutate(
    maternal_mortality_rate = dist3 / population * 100000,
    year = 2020
  ) %>%
  select(County, cnty_fips, maternal_mortality_rate, year)

# Combine 2019 and 2020 data
combined <- bind_rows(merged_2019, merged_2020)

# View final combined data
print(head(combined))
```

### 2.2 Merge Imputed Outcome to SDOH Data

```{r}
# Ensure COUNTYFIPS in subset_data is formatted as a 5-digit string
subset_data <- subset_data %>%
  mutate(
    countyfips = sprintf("%05d", as.integer(countyfips))
  )

# Join subset_data with combined on YEAR and COUNTYFIPS/cnty_fips
merged_data <- subset_data %>%
  left_join(
    combined,
    by = c("YEAR" = "year", "countyfips" = "cnty_fips")
  )

# Fill missing Maternal_mortality_rates in subset_data with values from combined
subset_data <- merged_data %>%
  mutate(
    Maternal_mortality_rate = ifelse(
      is.na(Maternal_mortality_rate),
      maternal_mortality_rate,
      Maternal_mortality_rate
    )
  ) %>%
  select(-maternal_mortality_rate,-countyfips, -YEAR,-County) # Remove unnecessary columns if desired
# View the updated subset_data
print(head(subset_data))
```
### 2.3 KNN Imputation of Other Variables
```{r}
if (!require("VIM")) install.packages("VIM")
library(VIM)



outcome_column <- subset_data$Maternal_mortality_rate
subset_data_no_outcome <- subset_data %>%
  select(-Maternal_mortality_rate)

# Perform KNN imputation on the predictors
subset_data_imputed <- kNN(subset_data_no_outcome, k = 5, imp_var = FALSE)

# Add the outcome column back
subset_data_imputed$outcome <- outcome_column

# Apply KNN imputation
subset_data_imputed <- kNN(subset_data, k = 5, imp_var = FALSE)



# View the first few rows of the imputed dataframe
head(subset_data_imputed)

subset_data=subset_data_imputed
```
## 3. Descriptive Analysis of Maternal Mortality Rates

It shows non-normal distribution.

```{r}
hist(subset_data$Maternal_mortality_rate,
     xlim = c(0, 5),  # Adjust the x-axis to a smaller range
     breaks = 200,      # Increase the number of bins for better granularity
     col = "lightblue", # Add color to make it visually appealing
     main = "Histogram of Maternal Mortality Rate",
     xlab = "Maternal Mortality Rate",
     ylab = "Frequency"
     )

```

The bulk is 0.There are `r sum(subset_data$Maternal_mortality_rate == 0)` of 0.

## 4. Linear Regression

We ran linear regression in this section.

### 4.1 VIF for multicollinearity
```{r}
model <- lm(Maternal_mortality_rate ~ ., data=subset_data)
vif_values <- vif(model)
print(vif_values)

```
The VIF values are relatively high for `Median_household_income` and `Percent_pop_under_1.37_of_poverty_threshold`. Doing the correlation test to check the multicolinearity.    

```{r}

# Spearman correlation
cor.test(subset_data$Median_household_income, subset_data$Percent_pop_under_1.37_of_poverty_threshold, method = "spearman")

```
The coefficients for the two variables are higher than 0.8. Drop `Percent_pop_under_1.37_of_poverty_threshold` and run the final model.

### 4.2 Linear Regression Model
```{r}
# Fit a model excluding Percent_pop_under_1.37_of_poverty_threshold
model_1 <- lm(Maternal_mortality_rate ~ . - Percent_pop_under_1.37_of_poverty_threshold, data = subset_data)

# View summary
summary(model_1)

```
The coefficients for `Percent_pop_American_Indian_and_Alaska_Native` and `Percent_pop_Black_and_African_American ` are statistically significant and positive, meaning that counties with higher percentage of American Indian and Black have higher maternal mortality rate.

The coefficient for `Median_household_income` is statistically significant and negative, indicating that Higher median household income is associated with a lower maternal mortality rate.


The coefficient for `Number_of_hospitals_with_ICU` is statistically significant and negative, suggesting that More hospitals with ICUs are associated with a lower maternal mortality rate.

The coefficient for `Percent_pop_30_44` is statistically significant and negative, indicating a higher percentage of women aged 30-44 is associated with a lower maternal mortality rate. It may be explained that compared with the base group (older than 44), this group has lower maternal mortality rate.

The coefficient for `Number_of_hospitals_with_obstetric` is statistically significant and positive, which might reflect referral bias, where areas with higher maternal mortality attract more obstetric services.



### 4.3 Diagnostic Plots

```{r}
par(mfrow = c(2, 2))  # Set up a 2x2 plot grid
plot(model_1)
```

```{r}
residuals <- residuals(model_1)
hist(residuals, 
     xlim=c(-5,5),
     breaks=100,
     main = "Histogram of Residuals", xlab = "Residuals")
```
The distribution of residual is slightly skewed. The skewness is minor and the sample size is relatively large. The central limit theorem can mitigate its impact on inference.

## 5. Random Forest Regression
We ran the random forest regressions in this section.
### 5.1 Hyperparameter Tuning using MSE as Metrics

```{r}
# Hyperparameter tuning for random forest regression tree 
# Define the tuning grid: include additional parameters
tuning_grid <- expand.grid(
  num.trees = c(100, 200, 300, 500),
  mtry = 1:(ncol(subset_data) - 1),
  splitrule = c("variance",'extratrees','maxstat'),    # Split rule for regression
  min.node.size = c(1, 5, 10),
  max.depth = c(0, 5, 10, 20)
)

# Randomly sample 60 combinations from the grid
set.seed(456)
random_combinations <- tuning_grid[sample(nrow(tuning_grid), 60), ]

# Cross-validation function
cross_validate <- function(data, formula, params, k = 5) {
  folds <- sample(1:k, nrow(data), replace = TRUE)
  scores <- numeric(k)
  
  for (i in 1:k) {
    # Split data into training and validation sets
    train_data <- data[folds != i, ]
    val_data <- data[folds == i, ]
    
    # Fit the model
    model <- ranger(
      formula = formula,
      data = train_data,
      splitrule = params$splitrule,
      num.trees = params$num.trees,
      mtry = params$mtry,
      min.node.size = params$min.node.size,
      max.depth = params$max.depth,
      num.threads=16
    )
    
    # Predict and calculate RMSE
    predictions <- predict(model, val_data)$predictions
    scores[i] <- sqrt(mean((val_data$Maternal_mortality_rate - predictions)^2))
  }
  
  # Return mean RMSE across folds
  mean(scores)
}

# Perform random search
results <- data.frame(random_combinations, RMSE = NA)

for (i in 1:nrow(random_combinations)) {
  if (i%%50==0)(
    cat(paste(".    ",i,"\r"))
  )
  else{
    cat(".")
  }
  params <- random_combinations[i, ]
  results$RMSE[i] <- cross_validate(
    data = subset_data,
    formula = Maternal_mortality_rate ~ .,
    params = params
  )
}
```
Best Model from Hyperparameter Tuning

```{r}

# Find the best combination
best_model <- results[which.min(results$RMSE), ]
best_model

```

### 5.2 Refit the final Random Forest model

```{r}
# Fit the Final Tree-Based Model
library(randomForest)
set.seed(123)
final_rf_model <- ranger(
  Maternal_mortality_rate ~ .,
  data = subset_data,
  num.trees = best_model$num.trees,
  splitrule = best_model$splitrule,
  mtry = best_model$mtry,
  min.node.size = best_model$min.node.size,
  max.depth = best_model$max.depth,
  num.threads=16,
  importance='permutation'
  )


```

```{r}
print(final_rf_model)
```

### 5.3 Parameter Importance 
```{r}
# Extract the importance metrics as a named vector
importance_metrics <- final_rf_model$variable.importance

# Convert to a data frame for easier manipulation
importance_df <- data.frame(
  Variable = names(importance_metrics),
  `%IncMSE` = importance_metrics
)

# Sort by `%IncMSE` in descending order
sorted_by_mse <- importance_df[order(-importance_df$`X.IncMSE`), ]

# View the sorted importance
print(sorted_by_mse)
```

The column `%IncMSE` stands for percentage increase in Mean Squared Error.
Measures how much the model’s prediction error increases when a particular variable is randomly permuted while keeping all other variables unchanged..
Higher values indicate that the variable is important for the model's predictive accuracy.It reflects the variable's contribution to the overall model performance.

```{r}
# Adjust margins for longer labels
par(mar = c(10, 5, 2, 2))  # Increase bottom margin

# Bar plot with adjusted margins
barplot(sorted_by_mse[, "X.IncMSE"],
        names.arg = rownames(sorted_by_mse),
        las = 2,
        col = "skyblue",
        main = "Variable Importance by %IncMSE",
        ylab = "%IncMSE",
        cex.names = 0.5)
```


### 5.4 Partial Dependence of Key Features

```{r}
# Partial dependence for multiple features
features <- rownames(sorted_by_mse)

# Loop to generate and print plots

for (feature in features) {
  pd <- partial(
    object = final_rf_model,
    pred.var = feature,
    train = subset_data,
    pred.fun = function(object, newdata) {
      predict(object, data = newdata)$predictions
    }
  )
  
  # Convert partial dependence to a data frame
  pd_df <- as.data.frame(pd)
  # Apply spline smoothing
  spline_fit <- smooth.spline(pd_df[,feature], pd_df$yhat, spar = 0.7)  # spar = smoothing parameter
  
  # Convert spline results to a data frame for ggplot
  spline_df <- data.frame(
    feature = spline_fit$x,
    yhat_smooth = spline_fit$y
  )
  colnames(spline_df)[1] <- feature
  # Create a proper ggplot
  print(ggplot(spline_df, aes_string(x = feature, y = "yhat_smooth")) +
    geom_line() +
    ggtitle(paste("Partial Dependence of", feature)) +
    xlab(feature) +
    ylab("Predicted Maternal Mortality Rate") +
    theme_minimal())
}
```

The partial dependence plot for `Percent_pop_18_29` shows with the increase of the percentage of this age group, the maternal mortality rate would go up, which can be explained that higher percentage of this group, higher pregnancy rate and higher mortality rate.

The partial dependece plots for `Percent_pop_American_Indian_and_Alaska_Native` and `Percent_pop_Black_and_African_American `,  `Median_household_income`, is the same with the result of the linear regression model.

The partial dependence plot for `Median_distance_to_nearest_obstetrics_department` shows an increase in the maternal mortality rate with the increase of the `Median_distance_to_nearest_obstetrics_department` increases, indicating that access to obstetric care is a critical factor. 

Socioeconomic Factors

The coefficients for Percent_pop_Black_and_African_American and Percent_pop_American_Indian_and_Alaska_Native are positive and significant, indicating that a higher percentage of these racial populations is associated with increased maternal mortality. This highlights the impact of systemic inequities and potential disparities in healthcare access.

Solutions:
Improve Healthcare Access: Expand healthcare services in minority-dense areas to reduce disparities.
Culturally Tailored Programs: Implement maternal health programs designed to meet the unique needs of these communities.
Provider Training: Invest in training healthcare providers to ensure culturally competent and bias-free care.

Demographic Trends
The coefficient for Percent_pop_30_44 is negatively significant, suggesting that a higher percentage of women aged 30-44 is associated with a lower maternal mortality rate. This may be because this group, compared to older groups (e.g., over 44 years), experiences fewer pregnancy-related complications. This finding implies that earlier pregnancies could potentially reduce maternal mortality risks.

Solutions:
Policy Support for Young Mothers: Introduce affordable childcare, flexible work arrangements, and extended parental leave policies to support younger women starting families.
Education and Awareness: Raise awareness about the risks of delayed childbearing and provide tailored prenatal care for older mothers.

Healthcare Access

The coefficient for `Number_of_hospitals_with_ICU` is negatively significant, indicating that a greater number of hospitals with ICU facilities is associated with lower maternal mortality rates. This underscores the importance of ICU availability in reducing severe maternal outcomes.

Solutions:
Expand ICU Facilities: Increase the number of hospitals with ICU care, especially in underserved and rural areas.
Upgrade Healthcare Infrastructure: Build or modernize healthcare facilities to ensure ICU services are available in high-risk regions.

Economic Disparities
The coefficient for `Median_household_income` is negative and significant, suggesting that counties with higher income levels tend to have lower maternal mortality rates. This highlights the influence of socioeconomic conditions on maternal health outcomes.

Solutions:
Support Low-Income Populations: Strengthen socioeconomic support systems for low-income communities through targeted interventions.
Healthcare Subsidies: Expand access to healthcare subsidies, prenatal care programs, and financial assistance for underserved populations.
Workforce Development: Implement programs to promote economic stability and job opportunities in high-risk counties.
